{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"{product}를 홍보하기 위한 좋은 문구를 추천해줘?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'텀블러를 홍보하기 위한 좋은 문구를 추천해줘?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(product=\"텀블러\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LLM 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/6khx28zs2bq8wjptklpbkj440000gn/T/ipykernel_47633/72671179.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
      "/var/folders/kh/6khx28zs2bq8wjptklpbkj440000gn/T/ipykernel_47633/72671179.py:6: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  print(llm1.predict(prompt))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "진희가 키우고 있는 동물은 강아지입니다.\n"
     ]
    }
   ],
   "source": [
    "llm1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5)\n",
    "\n",
    "\n",
    "prompt = \"진희는 강아지를 키우고 있습니다, 진희가 키우고 있는 동물은?\"\n",
    "\n",
    "print(llm1.predict(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kh/6khx28zs2bq8wjptklpbkj440000gn/T/ipykernel_47633/1326285245.py:8: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  completion = llm2.predict(prompt)\n",
      "/opt/anaconda3/envs/lct/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               \n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "\n",
    "llm2 = HuggingFaceHub(repo_id=\"google/flan-t5-small\",\n",
    "                      model_kwargs={\"temperature\": 0.8, \"max_length\":96})\n",
    "\n",
    "prompt = \"진희는 강아지를 키우고 있습니다, 진희가 키우고 있는 동물은?\"\n",
    "\n",
    "completion = llm2.predict(prompt)\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 모델 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.model_laboratory import ModelLaboratory\n",
    "\n",
    "model_lab = ModelLaboratory.from_llms([llm1, llm2])\n",
    "\n",
    "model_lab.compare(\"대한민국 가을을 몇월부터 몇월까지 일까?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 출력파서"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PydanticOutputParser : 입력된 데이터를 정의된 필드 타입에 맞게 자동으로 변환\n",
    "- SimpleJsonOutputParser : JSON 형태로 결과를 반환합니다. \n",
    "- CommaSeparatedListOutputParser : ,(comma)로 구분하여 결과 반환\n",
    "- DatetimeOutputParser : 날짜 시간 형태로 결과 반환\n",
    "- XMLOutputParser : XML형태로 결과 반환\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\",\n",
    "                 temperature=0.5,\n",
    "                 max_tokens = 2048\n",
    "                 )\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"7개의 팀을 보여줘 {subject}.\\n{format_instructions}\",\n",
    "    input_variables=['subject'],\n",
    "    partial_variables = {'format_instructions' : format_instructions}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"한국의 야구팀은?\"\n",
    "\n",
    "output = llm.predict(text=prompt.format(subject = query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['두산 베어스', 'LG 트윈스', '키움 히어로즈', '삼성 라이온즈', 'KIA 타이거즈', '롯데 자이언츠', 'NC 다이노스']\n"
     ]
    }
   ],
   "source": [
    "parsed_result = output_parser.parse(output)\n",
    "\n",
    "print(parsed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lct",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
